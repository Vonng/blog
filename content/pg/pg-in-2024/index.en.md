---
title: Looking Ahead to PostgreSQL in 2024
date: 2024-01-05
hero: /hero/pg-in-2024.jpg
author: |
  [JONATHAN KATZ](https://jkatz05.com/) | Translator: [Vonng](https://vonng.com) ([@Vonng](https://vonng.com/en/)) | [Original WeChat Article](https://mp.weixin.qq.com/s/OM8xhIFB3m95T1GCAQm1Ow)
summary: >
  This article is PostgreSQL core team member Jonathan Katz's outlook on the future of the PostgreSQL project in 2024, reviewing the progress PostgreSQL has made in recent years.
tags: [PostgreSQL,PG Ecosystem]
---

This article is PostgreSQL core team member Jonathan Katz's outlook on the future of the PostgreSQL project in 2024, reviewing the progress PostgreSQL has made in recent years.

> **Author**: Jonathan Katz, Principal Product Manager and Technical Lead at Amazon RDS, PostgreSQL Global Development Group core member and major contributor. Blog: https://jkatz05.com/.
>
> **Translator**: Vonng. Founder/CEO of PanJi Cloud Data, [**PostgreSQL**](http://mp.weixin.qq.com/s?__biz=MzU5ODAyNTM5Ng==&mid=2247485685&idx=1&sn=688f6d6d0f4128d7f77d710f04ff9024&chksm=fe4b3d2ec93cb438665b7e0d554511674091b2e486a70b8a3eb7e2c7a53681fb9834a08cb3c3&scene=21#wechat_redirect) expert and evangelist, author of open-source RDS PG — [**Pigsty**](http://mp.weixin.qq.com/s?__biz=MzU5ODAyNTM5Ng==&mid=2247485518&idx=1&sn=3d5f3c753facc829b2300a15df50d237&chksm=fe4b3d95c93cb4833b8e80433cff46a893f939154be60a2a24ee96598f96b32271301abfda1f&scene=21#wechat_redirect) author. Blog: https://vonng.com
>
> Click "View Original" to see the English original: https://jkatz05.com/post/postgres/postgresql-2024/

Among the questions I frequently hear, one is particularly profound: ***"Where is PostgreSQL heading?"*** — This is also a question I often ask myself. This question isn't limited to the technical aspects of the database kernel engine but concerns all aspects of the entire community — including related open-source projects, events, and community development. PostgreSQL is already widely popular and has been named [**"Database of the Year"**](https://db-engines.com/en/blog_post/106) by DB Engine for the fourth time. Despite this significant success, we still need to occasionally step back and think about PostgreSQL's future from a more macro perspective. While such thinking won't immediately bring significant changes, it provides important context for the community's ongoing work.

The New Year is an excellent time to think about **"PostgreSQL's future"**. I also have some thoughts on PostgreSQL's development direction in 2024. Here are my thoughts: this isn't a roadmap but my personal thoughts on PostgreSQL's development direction.

-------

## PostgreSQL Feature Development

At the [PGCon 2023 Developer Meeting](https://wiki.postgresql.org/wiki/PgCon_2023_Developer_Meeting), I proposed a topic titled "**What are the major challenges facing PostgreSQL users?**" This topic aimed to explore common user needs and evolving trends in database workloads to judge whether we're developing PostgreSQL in the right direction. Through multiple conversations and observations, I proposed three main feature categories:

- Availability
- Performance  
- Developer-oriented features

These feature groups will become work priorities for 2024 and even longer time periods. Next, I'll explore each feature category in more depth.

### Availability

For existing PostgreSQL users and potential users, improving availability is the most urgent need. This need isn't just ranked first but, without exaggeration, could also rank second and third. While restarting PostgreSQL can usually be completed quickly, in some extreme cases, this process might take too long. Additionally, long-duration write blocking, such as certain lock operations, can also be considered "downtime."

Most PostgreSQL users are satisfied with existing availability levels, but some workloads have extremely strict availability requirements. To better meet these requirements, we need additional development work. This article or this section focuses on this point: improving PostgreSQL to make it suitable for more environments with stringent availability requirements.

#### How Logical Replication Helps with Dual-Master, Blue-Green Deployment, Zero-Downtime Upgrades, and Other Workflows

For existing PostgreSQL users and those planning to migrate to PostgreSQL, improving availability is the most important need. This usually refers to [high availability](https://en.wikipedia.org/wiki/High_availability) — the database's ability to continue read and write operations during planned updates or unplanned interruptions. PostgreSQL already provides many features supporting high availability, such as streaming replication. However, achieving the highest level of availability usually requires additional services or tools like [Patroni](https://github.com/zalando/patroni).

I've talked to many users, and in most cases, they're satisfied with PostgreSQL's availability. But I've also discovered a new trend: some workloads now have increasingly high availability requirements — 15-30 second offline windows are no longer sufficient. This includes planned interruptions (like minor version upgrades, major version upgrades) and unplanned interruptions. Some users say their systems can only tolerate 1 second of unavailability at most. Initially, I was skeptical of such requirements, but after understanding the specific uses of these workloads, I believe 1 second is indeed a reasonable requirement.

In continuously improving PostgreSQL availability, [logical replication](https://www.postgresql.org/docs/current/logical-replication.html) is a key feature. Logical replication can stream changes from PostgreSQL databases in real-time to any system supporting PostgreSQL's logical replication protocol. Logical replication in PostgreSQL [has existed for some time](https://jkatz05.com/post/postgres/postgres-10-tribute/), and [recent versions](https://www.postgresql.org/about/news/postgresql-16-released-2715/) have brought significant improvements in availability, including new features in functionality and performance.

Logical replication plays a key role in PostgreSQL's major version upgrade process. Compared to traditional physical (or binary) replication, its major advantage is enabling cross-version data flow. For example, through logical replication, we can easily stream PostgreSQL 15 data changes to PostgreSQL 16 in real-time, significantly reducing downtime during upgrades. This approach has been successfully applied in [Instacart's zero-downtime major version upgrades](https://www.instacart.com/company/how-its-made/zero-downtime-postgresql-cutovers/). However, PostgreSQL still needs improvement in supporting such use cases and other high-availability scenarios. Future development is expected to further optimize support for [blue-green deployment](https://en.wikipedia.org/wiki/Blue-green_deployment) functionality to achieve more seamless data migration and application upgrades.

Besides use cases in major version upgrades, logical replication itself is also an important means of building high-availability systems. "**Multi-master replication**" is one typical application, allowing multiple database instances to simultaneously accept write operations and synchronize data changes between them. This pattern is especially suitable for systems sensitive to downtime (e.g., not accepting more than 1 second of unavailability). Its design goal is that when any write database has problems, applications can quickly switch to another available write database without waiting for it to be promoted to the new master. Building and managing such dual-active systems is extremely complex: it affects application design, requires users to provide strategies for managing write conflicts, and needs carefully designed fault-tolerant monitoring systems to ensure data integrity (e.g., what happens if an instance can't replicate its changes for hours?).

Major version upgrades and dual-active replication cases point us toward improving PostgreSQL's logical replication. [Amit Kapila](https://amitkapila16.blogspot.com/) is the leader in developing many logical replication features. This year, he and I jointly presented "[The Journey to Multi-Master Replication in PostgreSQL](https://www.postgresql.eu/events/pgconfeu2023/sessions/session/4783/slides/434/pgconfeu2023_active_active.pdf)" at a conference (with [video version](https://www.youtube.com/watch?v=jPp4XIY4XRw) available), deeply exploring why solutions for these use cases are crucial, PostgreSQL's achievements in logical replication, and work needed to better support these scenarios. The good news is that starting from PostgreSQL 16, we already have most of the basic modules to support dual-active replication, blue-green deployment, and zero-downtime major version upgrades. While these features might not all be integrated in the kernel, some extensions (like [`pgactive`](https://aws.amazon.com/blogs/database/using-pgactive-active-active-replication-extension-for-postgresql-on-amazon-rds-for-postgresql/) that I participated in developing) already provide these capabilities.

In 2024, multiple efforts aim to help close these feature gaps. For PostgreSQL 17 (standard disclaimer: these features might not be released), there's a focus on ensuring logical replication can work with key workflows (like [`pg_upgrade`](https://www.postgresql.org/docs/current/pgupgrade.html) and [high-availability systems](https://commitfest.postgresql.org/46/4423/)), support replication of more types of data changes (like [sequences](https://commitfest.postgresql.org/46/3823/)), extend support for more commands (like [DDL](https://commitfest.postgresql.org/46/3595/)), improve performance, and add features simplifying logical replication management (like node synchronization/re-synchronization).

These efforts will make PostgreSQL suitable for more types of workloads, especially scenarios with extremely stringent availability requirements, and simplify how users roll out new changes in production environments. While the road to improving logical replication functionality is still long, 2024 will undoubtedly bring more powerful features to PostgreSQL, helping users run PostgreSQL more efficiently in critical environments.

#### Reducing Locking

Another area related to availability is **schema maintenance operations** (i.e., [DDL](https://en.wikipedia.org/wiki/Data_definition_language) statements). For example, most forms of [`ALTER TABLE`](https://www.postgresql.org/docs/current/sql-altertable.html) impose [`ACCESS EXCLUSIVE`](https://www.postgresql.org/docs/current/explicit-locking.html#LOCKING-TABLES) locks on tables, preventing all concurrent access to those tables. For many users, this equals unavailability, even if it's only a subset of data. PostgreSQL lacks complete support for non-blocking/online schema maintenance operations, and as other relational databases begin supporting these features, this shortcoming becomes increasingly apparent.

While there are currently various tools and extensions supporting non-blocking schema updates, it would certainly be more convenient and performant if PostgreSQL could natively support a broader range of non-blocking schema changes. From a design perspective, we already have the foundation to develop this functionality, but it still needs time to implement. While I'm not sure if there are specific implementations currently in progress, I believe we should make more progress in this area in 2024: allowing users to execute most (or all) DDL commands without blocking writes.

#### Performance

Performance is a continuously evolving feature — we always pursue faster speeds. The good news is that PostgreSQL enjoys a reputation for vertical scaling capabilities — when you provide more hardware resources to a single instance, PostgreSQL scales gracefully. While horizontal scaling of read-write operations makes sense in some scenarios, we still need to ensure PostgreSQL can continue scaling as computing and memory resources increase.

Here's a more specific example: considering AWS EC2 instances with configurations up to [448 vCPU / 24TB memory](https://aws.amazon.com/ec2/instance-types/high-memory/) — can PostgreSQL fully utilize these resources on a single instance? We can set performance improvement goals based on hardware configurations PostgreSQL users currently and might use in the future, continuously improving PostgreSQL's overall performance.

In 2024, multiple efforts are already committed to continuing PostgreSQL's vertical scaling. One of the biggest efforts, and a multi-year project, is supporting DirectIO (DIO) and Asynchronous IO (AIO) in PostgreSQL. For details, I'll leave it to Andres Freund's presentation at [PGConf.EU](https://www.pgconf.eu/) on [the current state of adding AIO to PostgreSQL](https://anarazel.de/talks/2023-12-14-pgconf-eu-path-to-aio/path-to-aio.pdf). It looks like in 2024, we'll be closer to full AIO support.

Another work that interests me is [parallel recovery](https://wiki.postgresql.org/wiki/Parallel_Recovery). PostgreSQL users with heavy write workloads often delay [Checkpoints](https://www.postgresql.org/docs/current/sql-checkpoint.html) to reduce I/O load. For busy systems, if PostgreSQL crashes a considerable time after executing a Checkpoint, when PostgreSQL restarts, it enters "crash recovery" state: it re-executes all changes since the last Checkpoint to reach a consistent state — during crash recovery, PostgreSQL can neither read nor write, meaning it's unavailable. This is a problem for busy core systems: while PostgreSQL can accept concurrent writes, it can only use a single process when replaying changes. If a busy system crashes an hour after the last checkpoint, the system would need to be offline for hours catching up to reach a consistent state point to come back online!

One way to overcome this limitation is supporting "[Parallel Recovery](https://wiki.postgresql.org/wiki/Parallel_Recovery)" — the ability to replay WAL changes in parallel. At [PGCon 2023](https://www.pgcon.org/), Koichi Suzuki gave a [detailed presentation on how PostgreSQL can support parallel recovery](https://www.pgcon.org/events/pgcon_2023/sessions/session/392/slides/69/ParallelRecovery%20in%20PostgreSQL.pdf). This applies not only to crash recovery but also to any PostgreSQL WAL replay operations (e.g., PITR point-in-time recovery). While this is an extremely challenging problem, supporting parallel recovery helps PostgreSQL continue vertical scaling because users can further optimize for heavy write workloads and also mitigate the risk of "recovery online delay exceeding acceptable ranges."

This isn't a detailed list of performance features. There's much more work to be done on PostgreSQL server performance, including index optimization, improved locking mechanisms, full utilization of hardware acceleration, etc. Additionally, work on the client side (like drivers and connection pools) can also bring additional performance improvements to application interactions with PostgreSQL. Looking ahead to 2024, seeing the community's ongoing work, I believe PostgreSQL will have overall performance improvements across all areas.

### Developer Features

I consider "**developer features**" a fairly broad category, focusing on how users architect & build applications around PostgreSQL. This includes: SQL syntax, functions, [stored procedure language support](https://wiki.postgresql.org/wiki/PL_Matrix), and features helping users migrate from other database systems to PostgreSQL. A specific innovation example is the [`multirange`](https://www.postgresql.org/docs/current/rangetypes.html) data type introduced in PostgreSQL 14, which allows users to aggregate discontinuous **ranges** together. This feature is very practical — I personally used it to [reduce hundreds of lines of PL/pgSQL code to three lines](https://www.crunchydata.com/blog/better-range-types-in-postgres-14-turning-100-lines-of-sql-into-3) when implementing scheduling functionality. Developer features also concern how PostgreSQL supports emerging workloads: for example, [JSON or vectors](https://jkatz05.com/post/postgres/vectors-json-postgresql/).

It's worth noting that many developer feature innovations mainly appear in **Extensions**, which is precisely the advantage of PostgreSQL's extensible model. However, regarding the database server itself, PostgreSQL's release speed for some developer features has lagged compared to the past. For example, although PostgreSQL was [the first to include JSON as a queryable data type](https://jkatz05.com/post/postgres/vectors-json-postgresql/) among relational databases, it has begun to lag in implementing syntax and features defined by the SQL/JSON standard. PostgreSQL 16 released some syntax features in SQL/JSON, and 2024 will see more efforts implementing the SQL/JSON standard.

Speaking of this, we should focus on **developer features in PostgreSQL that cannot be implemented through extension plugins**, such as SQL standard features. My suggestion is to concentrate on features that other databases already have, such as further implementing the SQL/JSON standard (e.g., `JSON_TABLE`), system-level versioned tables (very useful for auditing, flashback, and temporal queries at specific time points), and module support (especially important for "packaging" stored procedures).

Additionally, considering the previously discussed availability and performance issues, we should continue efforts to simplify the process of migrating from other databases to PostgreSQL. In my daily work, I have the opportunity to learn about extensive content related to database migration: migration strategies from commercial databases to PostgreSQL. As we enhance PostgreSQL functionality, there are also many opportunities to simplify migration processes. This includes introducing existing functionality from other databases (e.g., global temporary tables, global partition indexes, [autonomous transactions](https://www.postgresql.org/message-id/f7470d5a-3cf1-4919-8404-5c4d91341a9f@tantorlabs.com)), and adding more functionality and performance optimizations to PL/pgSQL (such as batch data processing functions, [schema variables](https://commitfest.postgresql.org/46/1608/), [cached function metadata](https://commitfest.postgresql.org/46/4684/)). All of these will improve the PostgreSQL developer experience and make it easier for users of other relational databases to adopt PostgreSQL.

Finally, we need to understand how to continuously support emerging workloads from **AI/ML** data, particularly vector storage and retrieval. At the 2023 [PGCon](https://www.pgcon.org/) conference, although people hoped to see native vector support in PostgreSQL itself, there was consensus that implementing such functionality in extensions like [pgvector](https://github.com/pgvector/pgvector) could gain first-mover advantage and support these workloads more quickly ([this strategy seems to have worked](https://jkatz05.com/post/postgres/pgvector-overview-0.5.0/), [performing excellently on vector data](https://aws.amazon.com/blogs/database/accelerate-hnsw-indexing-and-searching-with-pgvector-on-amazon-rds-for-postgresql/)). [Given various characteristics of vector workloads](https://www.postgresql.eu/events/pgconfeu2023/sessions/session/4592/slides/435/pgconfeu2023_vectors.pdf), we can add some additional support in PostgreSQL to further support them: this includes optimizing the planner for handling [TOAST data in active query paths](https://www.postgresql.org/message-id/ad8a178f-bbe7-d89d-b407-2f0fede93144@postgresql.org), and exploring how to better support queries with many filtering conditions and `ORDER BY` clauses.

I'm confident that in 2024, PostgreSQL can make significant progress in these areas. We see massive new capabilities emerging in PostgreSQL's extension ecosystem; but even so, we can continue directly adding new features to PostgreSQL, making it easier to build applications.

### What About Security?

I want to quickly go over PostgreSQL's security features. PostgreSQL is well-known for having an excellent reputation in security-sensitive scenarios. But there are always many areas for improvement. In recent years, the PostgreSQL community has shown much interest and attention in introducing native support for [Transparent Data Encryption](https://wiki.postgresql.org/wiki/Transparent_Data_Encryption) (TDE). However, there are many other areas for innovation, such as supporting other authentication methods/mechanisms (mainly OIDC demand), or exploring possibilities for federated authorization models that allow PostgreSQL to inherit permission settings from other systems. While these features are all quite challenging currently, I recommend first supporting TDE at the "Per-Database" level. I don't want to expand too much here because there are already methods to meet these feature needs in PostgreSQL, but we should still work tirelessly to achieve complete native support.

Let's look at other directions PostgreSQL can focus on in 2024.

-------

## Extensions

PostgreSQL is designed to be **highly extensible**. You can add new functionality to PostgreSQL without forking the project. This includes new data types, index methods, ways to work with other database systems, utilities making PostgreSQL management easier, [additional programming language support](https://wiki.postgresql.org/wiki/PL_Matrix), and even [writing your own extension plugins](https://github.com/aws/pg_tle). People have built open-source communities and companies around specific PostgreSQL extensions (like [PostGIS](https://postgis.net/)); PostgreSQL's ability to support different types of workloads (geospatial, time-series, data analytics, artificial intelligence) with a single database is made possible by **extensions**. [Thousands of available PostgreSQL extensions](https://gist.github.com/joelonsql/e5aa27f8cc9bd22b8999b7de8aee9d47) become PostgreSQL's "force multipliers" — they allow users to quickly add functionality to databases while greatly promoting PostgreSQL's popularization and adoption.

However, this also creates a side effect: the "**extension sprawl**" phenomenon. How do users choose appropriate extensions? What's the level of support for extensions? How do you judge whether an extension has continuous active maintenance? How do you contribute to extensions? Even "where to download extensions" becomes a big problem. postgresql.org provides an [incomplete extension list](https://www.postgresql.org/download/products/6-postgresql-extensions/), the community also maintains some [extension packages](https://www.postgresql.org/download/), and there are several other PostgreSQL extension repositories to choose from (e.g., [PGXN](https://pgxn.org/), [dbdev](https://database.dev/), [Trunk](https://pgt.dev/)) and [pgxman](https://pgxman.com/).

One advantage of the PostgreSQL community is decentralization, widely distributed around the world. But we can do better to help users make informed choices in complex data management. I think 2024 is an opportunity where we can invest more resources in integrating and showcasing PostgreSQL extensions, helping users understand when to use which extensions, understanding their development maturity, and also providing better management support and maintenance resources for extension developers.

-------

## Community Building

When discussing community building visions for 2024, I feel deeply that we've made significant progress since I joined the PostgreSQL contributor community. The community performs excellently in [recognizing various types of contributors](https://www.postgresql.org/community/contributors/) (though there's still room for improvement) — not limited to code contributions but including all aspects of the project. Looking ahead, I want to emphasize three key areas: mentorship, diversity, equity, and inclusion ([DEI](https://en.wikipedia.org/wiki/Diversity,_equity,_and_inclusion)), and transparency, all crucial for the project's comprehensive development.

At the [PGCon 2023 Developer Meeting](https://wiki.postgresql.org/wiki/PgCon_2023_Developer_Meeting#What_are_the_big_challenges_for_our_users.3F_What_are_the_big_challenges_for_us_to_solve.3F), [Melanie Plageman](https://mastodon.social/@melanieplageman/) conducted an in-depth analysis of new contributor experiences and challenges. She mentioned numerous challenges, such as beginners needing to spend considerable time mastering basic knowledge, including using codebases and mailing lists for communication, and the effort required to submit patches to reviewable states. She also pointed out that providing constructive guidance (starting with reviewing patches) might be more challenging than writing code itself, while also discussing how to provide feedback effectively.

Regarding providing feedback, I want to quote an [excellent blog post](https://rhaas.blogspot.com/2023/12/praise-criticism-and-dialogue.html) by Robert Haas, where he particularly emphasizes the importance of giving praise while criticizing — this approach can produce significant effects and reminds us to maintain a supportive attitude even when criticizing.

Returning to Melanie's points, we should better implement mentorship programs throughout the community. Personally, I think I haven't done well enough in promoting the project, including helping more people contribute to [network infrastructure](https://www.postgresql.org/developer/related-projects/) and [release processes](https://www.postgresql.org/about/press/presskit16/). This isn't to say PostgreSQL lacks excellent mentors, but we can do better in helping people start contributing and finding mentors.

2024 will be the starting point for establishing better mentorship systems. We hope to experiment with some new ideas at [PGConf.dev 2024](https://2024.pgconf.dev/) in Vancouver in May.

> Before [PGConf.dev](https://www.pgconf.dev/) appeared, from 2007 to 2023, [PGCon](https://www.pgcon.org/) was the important event where PostgreSQL contributors gathered to discuss upcoming development cycles and key projects. PGCon was always organized by Dan Langille. After years of hard work, he decided to expand organizational responsibilities to a team and helped establish [PGConf.dev](https://www.pgconf.dev/).

[PGConf.dev](https://www.pgconf.dev/) is a conference specifically designed for those who want to contribute to PostgreSQL. The conference content covers PostgreSQL development work (including kernel and all related open-source projects like extensions and drivers), community building, and open-source thought leadership. A major feature of PGConf.dev is mentorship, with planned workshops on how to contribute to PostgreSQL. If you're looking for opportunities to contribute to PostgreSQL, I strongly recommend considering attending this event or [submitting presentation proposals](https://2024.pgconf.dev/cfp/)!

Next is the topic of how the PostgreSQL community progresses in diversity, equity, and inclusion ([DEI](https://en.wikipedia.org/wiki/Diversity,_equity,_and_inclusion)). I strongly recommend watching [Karen Jex](https://karenjex.blogspot.com/) and [Leticia Avila](https://mydbanotebook.org/)'s presentation at PGConf.eu 2023: [Trying to Be Barbie in Ken's Mojo Dojo Casa House](https://www.postgresql.eu/events/pgconfeu2023/schedule/session/4913-trying-to-be-barbie-in-kens-mojo-dojo-casa-house/): this is a profound talk about how to continue making the PostgreSQL community more inclusive. The community has made progress in this area (Karen and Leticia pointed out some initiatives that help), but we can do better. We should be proactive in handling feedback to ensure contributing to PostgreSQL is a welcoming experience. We can all take action, for example, promptly pointing out inappropriate behavior (such as sexism) when it occurs and explaining why the behavior is inappropriate.

Finally, there's the transparency issue. This might sound strange in the open-source realm since it's inherently open. But quite a few governance issues aren't discussed in public, and it would be helpful to understand decision-making processes. The [PostgreSQL Code of Conduct Committee](https://www.postgresql.org/about/policies/coc_committee/) provides an excellent example: how a community can maintain transparency on issues requiring sensitive handling. The committee publishes annual reports ([here's the 2022 report](https://www.postgresql.org/about/policies/coc/reports/2022/)), including general descriptions of cases and overall statistics. We can replicate this practice in many PostgreSQL teams — teams involved in tasks that might require confidentiality due to their sensitive nature.

-------

## Conclusion: This Article Should Have Been Shorter

Initially, I thought this article would be a short post that could be completed in a few hours. But several days later, I realized that wasn't the case...

Honestly, PostgreSQL is currently in a very good state. It remains popular, with its reputation for reliability, robustness, and performance solid as a rock. However, we can still do better, and it's exciting that the community is actively working to improve in various directions.

While the above represents what PostgreSQL can do in 2024 and beyond, PostgreSQL has already accomplished a great deal to get to where it is today. Asking "Where is PostgreSQL going?" actually provides us with an opportunity: to review the progress PostgreSQL has made in recent years and look forward to the future!